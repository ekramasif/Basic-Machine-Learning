{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding_Sequence_LSTM_Keras.preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekramasif/Basic-Machine-Learning/blob/main/Recurrent%20Neural%20Network/Embedding_Sequence_LSTM_Keras_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4pk2muJSvYz",
        "outputId": "a524e8c2-2489-4c45-9e78-25008d2c2570"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbHHVXbKXc4z"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(10, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpWAb8YXX44N",
        "outputId": "f77fa31b-8922-41fa-832d-a459fab0413f"
      },
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01260991, -0.03372312,  0.00194007, -0.0095757 , -0.03261369],\n",
              "       [-0.03920127, -0.03010396,  0.01364129, -0.00900034, -0.01983504],\n",
              "       [-0.04036004,  0.00333557,  0.04447658, -0.02548711, -0.00562143]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEzJFRzbYZ71",
        "outputId": "8fc34248-31c7-4068-fade-061ce53e10f1"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "sentence = ['‡¶è‡¶á ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡ßá ‡¶ú‡¶æ‡¶®‡¶æ ‡¶ó‡ßá‡¶≤‡ßã ‡¶¶‡ßá‡¶∂ ‡¶è‡¶∞ ‡¶ï‡¶∞‡ßã‡¶®‡¶æ ‡¶™‡¶∞‡¶ø‡¶∏‡ßç‡¶•‡¶ø‡¶§‡¶ø‡¶∞ ‡¶â‡¶®‡ßç‡¶®‡¶§‡¶ø ‡¶π‡ßü‡ßá‡¶õ‡ßá', \n",
        "            '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶æ‡¶ú‡ßá ‡¶Æ‡ßÅ‡¶ñ‡ßã‡¶∂‡¶ß‡¶æ‡¶∞‡ßÄ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶Ö‡¶≠‡¶æ‡¶¨ ‡¶®‡¶æ‡¶á', \n",
        "            '‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡¶ø‡¶® ‡¶¶‡¶ø‡¶® ‡¶¨‡ßã‡¶ï‡¶æ‡¶∞ ‡¶∞‡¶æ‡¶ú‡ßç‡¶Ø‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶∏‡¶ø‡¶§ ‡¶π‡¶ö‡ßç‡¶õ‡¶ø']\n",
        "\n",
        "tokenizer.fit_on_texts(sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences(sentence)\n",
        "\n",
        "sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
              " [14, 15, 16, 17, 18, 19],\n",
              " [20, 1, 1, 21, 22, 23, 24]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G10BENsTafAa",
        "outputId": "dfb869cd-61e7-46de-cbc5-b698d1ed949c"
      },
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01260991, -0.03372312,  0.00194007, -0.0095757 , -0.03261369],\n",
              "       [-0.03920127, -0.03010396,  0.01364129, -0.00900034, -0.01983504],\n",
              "       [-0.04036004,  0.00333557,  0.04447658, -0.02548711, -0.00562143]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF357AqLhRHO"
      },
      "source": [
        "from numpy import array\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dense, LSTM, Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cICBB2hTh5r7"
      },
      "source": [
        "# Real Life Example of Classification\n",
        "\n",
        "train_ex = ['‡¶™‡¶£‡ßç‡¶Ø ‡ßß‡ß¶‡ß¶% ‡¶Ö‡¶∞‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶á‡¶ú ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶Ü‡¶∏‡¶õ‡ßá ‡¶ì‡¶ü‡¶æ ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶®‡¶æ‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡ß™‡ß®',\n",
        "             '‡¶ú‡ßÅ‡¶§‡¶æ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡ßá‡¶∞ ‡¶õ‡¶ø‡¶≤ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶≠‡¶æ‡¶∞‡ßÄ ‡¶Æ‡¶®‡ßá ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶ú‡ßÅ‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶∂‡¶ï‡ßç‡¶§‡•§ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü‡¶ü‡¶ø ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá ‡¶Ø‡¶æ ‡¶ö‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶§‡¶æ‡¶á ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø  ‡¶ì‡¶≠‡¶æ‡¶∞‡¶Ö‡¶≤ ‡¶≠‡¶æ‡¶≤‡ßã',\n",
        "             '‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶ø‡¶∏‡ßç‡¶Æ‡¶ø‡¶§, ‡¶†‡¶ø‡¶ï ‡¶Ø‡ßá‡¶Æ‡¶®‡¶ü‡¶ø ‡¶ö‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶§‡ßá‡¶Æ‡¶®‡¶ü‡¶ø ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡•§‡•§ ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡•§',\n",
        "             '‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£...‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡•§ ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡•§',\n",
        "             '‡¶¨‡ßá‡¶∂‡¶ø ‡¶¨‡¶≤‡¶¨‡¶®‡¶æ ‡¶è‡¶ï‡¶ï‡¶•‡¶æ‡ßü ‡¶è‡¶ï‡¶∂‡¶§‡ßá ‡¶è‡¶ï‡¶∂‡•§ ‡¶¶‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ñ‡ßÅ‡¶¨‡¶á‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü, ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶≤‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø‡¶ï‡ßá‡•§',\n",
        "             '‡¶ñ‡ßÅ‡¶¨ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶¨‡¶≤‡¶æ ‡¶ö‡¶≤‡ßá ‡¶®‡¶æ‡•§ ‡¶ö‡¶æ‡¶á‡¶≤‡¶æ‡¶Æ ‡ß™‡ßß ‡¶Ü‡¶∞ ‡¶¶‡¶ø‡¶≤‡ßã ‡ß™‡ß¶‡•§‡•§‡¶ì‡¶®‡¶æ‡¶∞‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞‡¶æ‡¶á ‡¶≠‡¶æ‡¶≤‡ßã ‡¶∞‡¶ø‡¶≠‡¶ø‡¶â ‡¶¶‡ßá‡ßü ‡¶ï‡¶æ‡¶∏‡ßç‡¶ü‡¶Æ‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶®‡ßç‡¶Ø‡ßá',\n",
        "             '‡¶π‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶Ö‡¶®‡ßá‡¶ï ‡¶Ü‡¶® ‡¶á‡¶ú‡¶ø ‡¶™‡¶æ ‡¶¨‡¶æ‡¶ï‡¶æ‡¶§‡ßá ‡¶™‡ßç‡¶∞‡¶¨‡ßç‡¶≤‡ßá‡¶Æ ‡¶π‡ßü',\n",
        "             '‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶è‡¶∞ ‡¶Æ‡¶§ ‡¶è‡¶á ‡¶∞‡¶ï‡¶Æ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶Ü‡¶∂‡¶æ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡ßü ‡¶®‡¶æ',\n",
        "             '‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶§‡ßã ‡¶∏‡¶¨‡¶∏‡¶Æ‡ßü‡¶á ‡¶≠‡¶æ‡¶≤‡ßã ‡¶¨‡¶æ‡¶ü ‡¶°‡ßá‡¶≤‡¶ø‡¶≠‡¶æ‡¶∞‡¶ø ‡¶¨‡¶æ‡¶ú‡ßá ‡¶õ‡¶ø‡¶≤‡ßãüò°üò°üò° ‡¶Ø‡ßá‡¶¶‡¶ø‡¶® ‡¶¶‡ßá‡ßü‡¶æ‡¶∞ ‡¶ï‡¶•‡¶æ ‡¶è‡¶∞ ‡ß® ‡¶¶‡¶ø‡¶® ‡¶™‡¶∞ ‡¶¶‡¶ø‡¶õ‡ßá...',\n",
        "             '‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶∏‡ßá‡¶≤‡¶æ‡¶∞‡•§ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶¶‡¶ø‡ßü‡¶æ ‡¶¨‡¶≤‡ßç‡¶≤‡¶æ‡¶Æ ‡¶∏‡¶æ‡¶á‡¶ú ‡¶Ø‡¶æ‡¶§‡ßá ‡¶â‡¶≤‡ßç‡¶ü‡ßã‡¶™‡¶æ‡¶≤‡ßç‡¶ü‡¶æ ‡¶®‡¶æ ‡¶Ü‡¶∏‡ßá‡•§ ‡¶ï‡ßá‡¶â ‡¶Ö‡¶∞‡¶°‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶π‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§‡•§'\n",
        "             ]\n",
        "\n",
        "# Reviews -- negative = 0 || positive = 1 (class/labels)\n",
        "train_label = array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iBFjv-kbkdLB",
        "outputId": "b6709af8-aa2c-4c37-af7e-7bd0cb81e621"
      },
      "source": [
        "train_ex[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‡¶¨‡ßá‡¶∂‡¶ø ‡¶¨‡¶≤‡¶¨‡¶®‡¶æ ‡¶è‡¶ï‡¶ï‡¶•‡¶æ‡ßü ‡¶è‡¶ï‡¶∂‡¶§‡ßá ‡¶è‡¶ï‡¶∂‡•§ ‡¶¶‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ñ‡ßÅ‡¶¨‡¶á‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü, ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶≤‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø‡¶ï‡ßá‡•§'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWv_Zwjkjy-",
        "outputId": "d30ec566-688c-45cb-d992-7a158e5b2c3e"
      },
      "source": [
        "# tokenization and converting words into sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_ex)\n",
        "dense_train_ex = tokenizer.texts_to_sequences(train_ex)\n",
        "\n",
        "dense_train_ex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[14, 15, 16, 17, 5, 6, 18, 19, 20, 21, 22, 7, 5, 23, 24],\n",
              " [8, 25, 26, 27, 28, 29, 30, 8, 9, 31, 32, 10, 33, 34, 11, 35, 36, 37, 1],\n",
              " [38, 39, 10, 40, 11, 41, 42, 2, 3, 2, 43],\n",
              " [44, 2, 45, 46, 47, 4, 48, 49],\n",
              " [50, 51, 52, 53, 54, 55, 56, 57, 4, 2, 58, 9, 59, 60],\n",
              " [61, 62, 1, 63, 64, 7, 65, 66, 67, 68, 69, 70, 1, 71, 72, 73, 74, 75],\n",
              " [76, 77, 78, 79, 80, 81, 82, 83, 84],\n",
              " [3, 12, 85, 86, 87, 4, 88, 89, 90, 13],\n",
              " [3, 91, 92, 1, 93, 94, 95, 96, 97, 98, 99, 12, 100, 101, 102, 103],\n",
              " [104, 105, 106, 107, 108, 6, 109, 110, 13, 111, 112, 113, 114, 115, 116, 117]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJClhSRVhVA4"
      },
      "source": [
        "# def FindMaxLength(dense_train_ex):\n",
        "#     maxList = max((x) for x in dense_train_ex)\n",
        "#     maxLength = max(len(x) for x in dense_train_ex )\n",
        "  \n",
        "#     return maxList, maxLength\n",
        "      \n",
        "# # Driver Code\n",
        "# print(FindMaxLength(dense_train_ex))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I2K785Qjm7x"
      },
      "source": [
        "# print(max(map(len, dense_train_ex)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grxvy74GlyFl",
        "outputId": "689baaef-2f31-4152-cf0a-1f1b762fc0dc"
      },
      "source": [
        "def longest(dense_train_ex):\n",
        "    longest_list = max(len(elem) for elem in dense_train_ex)\n",
        "    return longest_list\n",
        "\n",
        "print(longest(dense_train_ex))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFo1jnbsoxFy",
        "outputId": "eacd32c6-844e-4a56-81f0-f788906263ee"
      },
      "source": [
        "def largest(arr,n):\n",
        "  \n",
        "    # Initialize maximum element\n",
        "    max = dense_train_ex[0]\n",
        "  \n",
        "    # Traverse array elements from second\n",
        "    # and compare every element with \n",
        "    # current max\n",
        "    for i in range(1, n):\n",
        "        if dense_train_ex[i] > max:\n",
        "            max = dense_train_ex[i]\n",
        "    return max\n",
        "  \n",
        "# Driver Code\n",
        "n = len(dense_train_ex)\n",
        "Ans = largest(dense_train_ex,n)\n",
        "print (\"Largest in given array is\",Ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest in given array is [104, 105, 106, 107, 108, 6, 109, 110, 13, 111, 112, 113, 114, 115, 116, 117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AgdiZbTnIfZ",
        "outputId": "78f6166e-41fe-4f1e-82f3-b28c3fa867d1"
      },
      "source": [
        "# padding the training documents in order to make them equal length\n",
        "MAX_LENGTH = 19\n",
        "\n",
        "padded_train_ex = pad_sequences(dense_train_ex, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "for pd_sen in padded_train_ex:\n",
        "  print(pd_sen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14 15 16 17  5  6 18 19 20 21 22  7  5 23 24  0  0  0  0]\n",
            "[ 8 25 26 27 28 29 30  8  9 31 32 10 33 34 11 35 36 37  1]\n",
            "[38 39 10 40 11 41 42  2  3  2 43  0  0  0  0  0  0  0  0]\n",
            "[44  2 45 46 47  4 48 49  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[50 51 52 53 54 55 56 57  4  2 58  9 59 60  0  0  0  0  0]\n",
            "[61 62  1 63 64  7 65 66 67 68 69 70  1 71 72 73 74 75  0]\n",
            "[76 77 78 79 80 81 82 83 84  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 3 12 85 86 87  4 88 89 90 13  0  0  0  0  0  0  0  0  0]\n",
            "[  3  91  92   1  93  94  95  96  97  98  99  12 100 101 102 103   0   0\n",
            "   0]\n",
            "[104 105 106 107 108   6 109 110  13 111 112 113 114 115 116 117   0   0\n",
            "   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1c60e4wpISB",
        "outputId": "073a8cc7-7679-4ccc-a63f-7962860feaa4"
      },
      "source": [
        "def largest(arr,n):\n",
        "  \n",
        "    # Initialize maximum element\n",
        "    max = Ans[0]\n",
        "  \n",
        "    # Traverse array elements from second\n",
        "    # and compare every element with \n",
        "    # current max\n",
        "    for i in range(1, n):\n",
        "        if Ans[i] > max:\n",
        "            max = Ans[i]\n",
        "    return max\n",
        "  \n",
        "# Driver Code\n",
        "n = len(Ans)\n",
        "Ans1 = largest(Ans,n)\n",
        "print (\"VOCAB_SIZE:\",Ans1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB_SIZE: 117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu9NqNL9n3Zb",
        "outputId": "6db9a090-cbed-4813-bd8d-bcfb63c8867a"
      },
      "source": [
        "# Model Declaration\n",
        "VOCAB_SIZE = 118\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding Layer\n",
        "embedding_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=8, input_length=MAX_LENGTH)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "# # Flatten Layer\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(units=160, activation='relu'))\n",
        "# model.add(Dense(units=80, activation='relu'))\n",
        "# model.add(Dense(units=40, activation='relu'))\n",
        "# model.add(Dense(units=10, activation='relu'))\n",
        "\n",
        "# LSTM - for better performance\n",
        "# model.add(LSTM(units=128))\n",
        "\n",
        "# Bidirectional LSTM\n",
        "forward_layers = LSTM(units=128, return_sequences=False)\n",
        "backward_layers = LSTM(units=128, return_sequences=False, go_backwards=True)\n",
        "model.add(Bidirectional(layer=forward_layers, backward_layer=backward_layers))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 19, 8)             944       \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               140288    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 141,489\n",
            "Trainable params: 141,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InvCtAjsrxPX",
        "outputId": "52cdc40f-b952-462c-a6dc-3a3007dea940"
      },
      "source": [
        "model.fit(padded_train_ex, train_label, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2500 - acc: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2496 - acc: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2490 - acc: 0.9000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2484 - acc: 0.6000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2476 - acc: 0.8000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2466 - acc: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2453 - acc: 0.9000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2437 - acc: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2416 - acc: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2389 - acc: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2354 - acc: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2306 - acc: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2241 - acc: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2153 - acc: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2031 - acc: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1865 - acc: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1639 - acc: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1342 - acc: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0979 - acc: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0599 - acc: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0275 - acc: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.8880e-04 - acc: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.9499e-04 - acc: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.6524e-05 - acc: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.2248e-05 - acc: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0122e-05 - acc: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2055e-05 - acc: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.2657e-05 - acc: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7141e-05 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.4742e-05 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.5904e-06 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6736e-06 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3376e-06 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5752e-06 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.5149e-06 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3963e-06 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.8349e-07 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3345e-07 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 9.2499e-07 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9635e-06 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6504e-06 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.4752e-07 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6687e-07 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1122e-07 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6732e-07 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.3606e-07 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4695e-06 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.7499e-07 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.2721e-07 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.9868e-08 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.6665e-08 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.2479e-07 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6179e-07 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.6014e-07 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.0055e-07 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.1974e-07 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6032e-07 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.1426e-08 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.8357e-08 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6908e-08 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.7651e-08 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8452e-08 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.9817e-08 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0013e-07 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2919e-07 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3923e-07 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2340e-07 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.4727e-08 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.8338e-08 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.9817e-08 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.8535e-08 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2425e-08 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9803e-08 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9556e-08 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.0963e-08 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.3458e-08 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.6590e-08 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9834e-08 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.2701e-08 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.4736e-08 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5631e-08 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.5317e-08 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.3935e-08 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1801e-08 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.9241e-08 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.6613e-08 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.4156e-08 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2038e-08 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0326e-08 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9040e-08 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8192e-08 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7722e-08 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7561e-08 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7658e-08 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7940e-08 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8310e-08 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8720e-08 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9078e-08 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f819c6a4ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBAB4FT4sKO9",
        "outputId": "805efaee-e9e0-451b-c0de-892b5d207b00"
      },
      "source": [
        "# Testing\n",
        "test_ex = ['‡¶¶‡¶æ‡¶Æ‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶π‡¶≤‡ßá‡¶ì ‡¶Æ‡¶æ‡¶®‡ßá ‡¶≠‡¶æ‡¶≤‡ßã, ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú ‡¶ï‡ßá', \n",
        "           '‡¶ú‡ßÅ‡¶§‡¶æ‡¶ü‡¶ø ‡¶π‡¶æ‡¶§‡ßá ‡¶™‡ßá‡ßü‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶á ‡¶¨‡¶ø‡¶∏‡ßç‡¶Æ‡¶ø‡¶§', \n",
        "           '‡¶è‡¶ï‡¶¶‡¶Æ ‡¶¨‡¶æ‡¶ú‡ßá, ‡¶Æ‡¶®‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶π‡¶≤‡¶æ‡¶Æ üò°',\n",
        "           '‡¶è‡¶§‡ßã ‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶™‡ßç‡¶∞‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶™‡¶¨‡ßã ‡¶Ü‡¶∂‡¶æ ‡¶ï‡¶∞‡¶ø ‡¶®‡¶ø']\n",
        "\n",
        "# tokenization and converting words into sequence\n",
        "dense_test_ex = tokenizer.texts_to_sequences(test_ex)\n",
        "\n",
        "# padding the test documents\n",
        "padded_test_ex = pad_sequences(dense_test_ex, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "prediction = model.predict(padded_test_ex)\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9956939 ]\n",
            " [0.99304175]\n",
            " [0.99197876]\n",
            " [0.01243237]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuxW_bwduAqO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}